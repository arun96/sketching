import java.io.File;
import java.io.FileInputStream;
import java.io.PrintWriter;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Random;
import java.util.Scanner;
import java.util.TreeSet;
import java.util.*;
import java.lang.*;
import java.util.stream.Collectors;
import java.util.Collection;
import java.nio.charset.StandardCharsets;

// GUAVA
import com.google.common.hash.*;
import com.google.common.hash.Hashing;
import com.google.common.hash.HashFunction;

// Heirachical Clustering Java
import com.apporiented.algorithm.clustering.*;
import com.apporiented.algorithm.clustering.visualization.*;

public class ReadScreenerClusterNovel {
  // Key Variables
  int readLen;
  int k;
  double readErr;
  int targetMatches;
  String genomeFolder;
  String readFolder;
  String[] genomeNames;
  String[] readSets;
  int numGenomes;
  int numReadSets;
  ArrayList<HashSet<Integer>> sketch_hash;
  int window;

  // Main function for screening reads
  // This will take in both a cluster and a screen (the original screen)
  ReadScreenerClusterNovel(ScreenGenerator sg, ClusterGenerator cg) throws Exception
  {

    // Get the sketch and experiment parameters saved
    this.readLen = Settings.READ_LENGTH;
    this.readErr = Settings.READ_ERROR;
    this.genomeFolder = Settings.GENOME_FOLDER;
    this.readFolder = Settings.READS_FOLDER;
    this.genomeNames = Settings.GENOMES;
    this.readSets = Settings.READ_SETS;
    this.k = Settings.K;
    // The sketch generated by the ScreenGenerator
    this.sketch_hash = sg.sketch_hash;
    this.numGenomes = genomeNames.length;
    this.numReadSets = readSets.length;
    // 0 if MinHash or uniform, >0 if Minimizer-based
    this.window = sg.window;

    // Print Sketch Sizes
    for (int a = 0; a < numGenomes; a++)
    {
      System.out.println(genomeNames[a] + " " + sketch_hash.get(a).size());
    }

    // TODO - add option to screen reads independently of the genomes
    // Add ability to track classifications

    System.out.println("Screening Reads - read results will be saved in: " + Settings.READ_LOCATION);

    // TODO - add something to store the classifications

    // Track total reads, assignments, insufficient, and ties
    int[] totalReads = new int[numReadSets];
    int[] insufCounts = new int[numReadSets];
    int[] tieCounts = new int[numReadSets];

    // Loading reads in specified numbers
    if (Settings.IN_CHUNKS){

      // For each organism/element's readset
     for (int r = 0; r < numReadSets; r++){

       boolean fully_read = false;

       int chunk_count = 0;

       int read_start = 0;

       while (!fully_read){

         ArrayList<String> reads = getReadsChunk(readFolder + readSets[r], chunk_count*Settings.CHUNK, Settings.CHUNK);

         int numReads = reads.size();

         //Screen these reads
         ParallelScreenerClusterNovel ps = new ParallelScreenerClusterNovel(sketch_hash, reads, window, r, read_start, cg);
         ps.run();

         // Counts for this readset
         totalReads[r] += ps.totalReads;
         insufCounts[r] += ps.insuf.intValue();
         tieCounts[r] += ps.ties.intValue();

         // Print update
         if (Settings.CHUNK_UPDATES) {
           System.out.println(totalReads[r]);
         }

         // We have reached the end of the file
         if (numReads < Settings.CHUNK) {
           fully_read = true;
           break;
         }

         // Update read count
         read_start += numReads;

         // Move to next set of reads
         chunk_count++;

       }

       // Print summary
       // TODO - fix this for read sets distinct from genomes
       System.out.println(readSets[r]);
       System.out.println(totalReads[r] + " " + insufCounts[r] + " " + tieCounts[r]);

     }

    // Load file by file
    } else {

      // For each organism/element's readset
     for (int r = 0; r < numGenomes; r++) {

       // Version for automatic loading
       ArrayList<String> reads = getReads(readFolder + readSets[r]);

       int read_start = 0;

       // For each read in the readset
       int numReads = reads.size();

       ParallelScreenerClusterNovel ps = new ParallelScreenerClusterNovel(sketch_hash, reads, window, r, read_start, cg);
       ps.run();
       // Counts for this readset
       totalReads[r] = ps.totalReads;
       insufCounts[r] = ps.insuf.intValue();
       tieCounts[r] = ps.ties.intValue();

       // Print summary
       // TODO - fix this for read sets distinct from genomes
       System.out.println(readSets[r]);
       System.out.println(totalReads[r] + " " + insufCounts[r] + " " + tieCounts[r]);
     }

    }

    // Whole experiment summary
    System.out.println("Printing Results...");
    System.out.println("Number of Reads:");
    System.out.println(Arrays.toString(totalReads));
    System.out.println("Number Not Classified:");
    System.out.println(Arrays.toString(insufCounts));

    // Print misclassification matrix -  this is now done in post processing
    // printMatrix(miscount_matrix);

    //Save results
    saveResults(Settings.OUTPUT_FILE, readSets, genomeNames, sketch_hash, totalReads, insufCounts, tieCounts);
  }

  // ----- I/O HELPER FUNCTIONS ------
  // Load Reads from a given file
  ArrayList<String> getReads(String fn) throws Exception
  {
    // ArrayList to store reads
    ArrayList<String> read_list = new ArrayList<String>();

    // Scan file
    Scanner input = new Scanner(new FileInputStream(new File(fn)));

    // While there is another line
    while(input.hasNext())
    {
      String line = input.nextLine();
      // If line is empty or line starts with '>', it is not a read and we continue
      if(line.length() == 0 || line.startsWith(">"))
      {
        continue;
      }
      // Else, add read to the reads ArrayList
      read_list.add(line.toUpperCase());
    }
    // List with all reads
    return read_list;
  }

  // Load a specified section of reads from a given file
  ArrayList<String> getReadsChunk(String fn, int start_point, int num_reads) throws Exception
  {
    // ArrayList to store reads
    ArrayList<String> read_list = new ArrayList<String>();

    // Scan file
    Scanner input = new Scanner(new FileInputStream(new File(fn)));

    // Counters to get the current chunk of reads
    int counter = 0;
    int start = (Settings.READ_LINES*start_point);
    int limit = start + (Settings.READ_LINES*num_reads);

    // While there is another line
    while(input.hasNext())
    {
      String line = input.nextLine();

      // If line has a valid read
      if ((line.length() > 0) && !(line.startsWith(">"))) {
        // If read is in desired range/chunk
        if ((counter >= start) && (counter <= limit)) {
          read_list.add(line.toUpperCase());
        }
      }
      counter++;

      // Break once you have crossed that chunk
      if (counter > limit){
        break;
      }
    }
    // List with all reads
    return read_list;
  }

  // Helper function to write results to file
  void saveResults(String filename, String[] readSets, String[] genomeNames, ArrayList<HashSet<Integer>> sketch_hash, int[] totalReads, int[] insufCounts, int[] tieCounts) throws Exception
  {
    PrintWriter out = new PrintWriter(new File(filename));
    System.out.println("Saving results...");
    out.println("Genome Sketches:");
    for (int i = 0; i < genomeNames.length; i++)
    {
      out.println(genomeNames[i] + " " + sketch_hash.get(i).size());
    }
    out.println("Read Screening Results:");
    for (int i = 0; i < readSets.length; i++)
    {
      out.println(readSets[i]);
      out.println(totalReads[i] + " " + insufCounts[i] + " " + tieCounts[i]);
    }
    out.close();
  }

  // Print the misclassified matrix
  public void printMatrix(int[][] matrix) {
    for (int row = 0; row < matrix.length; row++) {
        for (int col = 0; col < matrix[row].length; col++) {
            System.out.printf("%4d", matrix[row][col]);
        }
        System.out.println();
    }
  }
}
